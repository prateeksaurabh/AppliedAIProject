{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Homework_LSTM_Amazon_fine_food.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljFWPHECeqR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import re\n",
        "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Eb3bCO3iOzW",
        "colab_type": "text"
      },
      "source": [
        "How to read csv file from drive i followed this link https://stackoverflow.com/questions/53619189/read-file-from-drive-in-google-colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB1IoQwQgl4I",
        "colab_type": "code",
        "outputId": "68c8e0d2-79ff-4dce-a060-78749d3cc86e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux7MWobpin6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "#data = pd.read_csv(\"/content/drive/My Drive/Reviews.csv\")\n",
        "con = sqlite3.connect(r\"/content/drive/My Drive/database.sqlite\")\n",
        "data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3\"\"\",con)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G1QU0BpjJe8",
        "colab_type": "code",
        "outputId": "0629f0ac-cbaf-49c1-be60-6d1cf6822594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "print (data)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Id  ...                                               Text\n",
            "0            1  ...  I have bought several of the Vitality canned d...\n",
            "1            2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
            "2            3  ...  This is a confection that has been around a fe...\n",
            "3            4  ...  If you are looking for the secret ingredient i...\n",
            "4            5  ...  Great taffy at a great price.  There was a wid...\n",
            "...        ...  ...                                                ...\n",
            "525809  568450  ...  Great for sesame chicken..this is a good if no...\n",
            "525810  568451  ...  I'm disappointed with the flavor. The chocolat...\n",
            "525811  568452  ...  These stars are small, so you can give 10-15 o...\n",
            "525812  568453  ...  These are the BEST treats for training and rew...\n",
            "525813  568454  ...  I am very satisfied ,product is as advertised,...\n",
            "\n",
            "[525814 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svKxFCdCvnPf",
        "colab_type": "text"
      },
      "source": [
        "The below code i am copying from my own assignment (Assignment number 4 from naive bayes where we already performed few data cleaning,data deplication etc processes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXbv0TYlvmW7",
        "colab_type": "code",
        "outputId": "bdcaa940-dfeb-4581-f3c5-4fae88d888d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Change Score with 1 n 2 as -ve and 4 n 5 as +ve\n",
        "\n",
        "def chng_to_0_or_1 (Score):\n",
        "    if Score ==4 or Score ==5:\n",
        "        return 1\n",
        "    elif Score ==1 or Score ==2:\n",
        "        return 0\n",
        "    else:# Thus in case by some mistake any data is their with rating 6 or 7 etc due to some error is removed\n",
        "        pass\n",
        "currentScore = data[\"Score\"]\n",
        "new_Score = currentScore.map(chng_to_0_or_1)\n",
        "data[\"Score\"] = new_Score\n",
        "print (\"Number of data points available\")\n",
        "print (data.shape)#Gives original number of data points available\n",
        "\n",
        "\n",
        "#2 Data Cleaning a.) Getting rid of duplicates and b.) if helpnessdenominator < helpfulnessnumerator\n",
        "\n",
        "\n",
        "data = data.drop_duplicates(subset = [\"UserId\",\"ProfileName\",\"HelpfulnessNumerator\",\"HelpfulnessDenominator\",\"Score\",\"Time\",\"Summary\",\"Text\"], keep='first', inplace=False)\n",
        "print (\"Number of data points after removing duplicates\")\n",
        "print (data.shape)#Gives data points are deduplication\n",
        "\n",
        "# Reference: Copied from above cell  final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n",
        "data=data[data.HelpfulnessNumerator<=data.HelpfulnessDenominator]\n",
        "print (\"Number of data points after removing where HelpfulnessNumerator is more than HelpfulnessDenominator \")\n",
        "print (data.shape)\n",
        "\n",
        "#3 Preprocessing begins\n",
        "\n",
        "#Convert to lower case,convert shortcut words to proper words, remove Special Character\n",
        "\n",
        "#i) Convert to lower case:\n",
        "data[\"Text\"] =  (data[\"Text\"].str.lower())\n",
        "data[\"Summary\"] =  (data[\"Summary\"].str.lower())\n",
        "\n",
        "#ii) Convert Shortcuts words to proper words\n",
        "#List of Words are:https://en.wikipedia.org/wiki/Wikipedia:List_of_English_contractions\n",
        "#Reference:https://stackoverflow.com/questions/39602824/pandas-replace-string-with-another-string\n",
        "data['Text'] = data['Text'].replace({\"ain't\":\"am not\",\"amn't\":\"am not\",\"aren't\":\"are not\", \\\n",
        "\"can't\":\"cannot\",\"cause\":\"because\",\"could've\":\"could have\",\"couldn't\":\"could not\",\"couldn't've\":\"could not have\", \\\n",
        "\"daren't\":\"dare not\",\"daresn't\":\"dare not\",\"dasn't\":\"dare not\",\"didn't\":\"did not\",\"doesn't\":\"does not\", \\\n",
        "\"don't\":\"do not\",\"e'er\":\"ever\",\"everyone's\":\"everyone is\",\"finna\":\"fixing to\",\"gimme\":\"give me\", \\\n",
        "\"gonna\":\"going to\",\"gon't\":\"go not\",\"gotta\":\"got to\",\"hadn't\":\"had not\",\"hasn't\":\"has not\",\"haven't\":\"have not\",\\\n",
        "\"he'd\":\"he had\",\"he'll\":\"he shall\",\"he's\":\"he has\",\"he've\":\"he have\",\"how'd\":\"how did\",\"how'll\":\"how will\",\\\n",
        "\"how're\":\"how are\",\"how's\":\"how has\",\"I'd\":\"I had\",\"I'll\":\"I shall\",\"I'm\":\"I am\",\"I'm'a\":\"I am about to\",\\\n",
        "\"I'm'o\":\"I am going to\",\"I've\":\"I have\",\"isn't\":\"is not\",\"it'd\":\"it would\",\"it'll\":\"it shall\",\"it's\":\"it has\",\\\n",
        "\"let's\":\"let us\",\"mayn't\":\"may not\",\"may've\":\"may have\",\"mightn't\":\"might not\",\"might've\":\"might have\",\\\n",
        "\"mustn't\":\"must not\",\"mustn't've\":\"must not have\",\"must've\":\"must have\",\"needn't\":\"need not\",\"ne'er\":\"never\",\\\n",
        "\"o'clock\":\"of the clock\",\"o'er\":\"\",\"ol'\":\"old\",\"oughtn't\":\"ought not\",\"shalln't\":\"shall not\",\"shan't\":\"shall not\",\\\n",
        "\"she'd\":\"she had\",\"she'll\":\"she shall\",\"she's\":\"she is\",\"should've\":\"should have\",\"shouldn't\":\"should not\",\\\n",
        "\"shouldn't've\":\"should not have\",\"somebody's\":\"somebody has\",\"someone's\":\"someone has\",\"something's\":\"something has\",\\\n",
        "\"that'll\":\"that will\",\"that're\":\"that are\",\"that's\":\"that is\",\"that'd\":\"that would\",\"there'd\":\"there had\",\\\n",
        "\"there'll\":\"there shall\",\"there're\":\"there are\",\"there's\":\"there is\",\"these're\":\"hese are\",\"they'd\":\"they had\",\\\n",
        "\"they'll\":\"they will\",\"they're\":\"they are\",\"they've\":\"they have\",\"this's\":\"\",\"those're\":\"those are\",\"tis\":\"it is\",\\\n",
        "\"twas\":\"it was\",\"wasn't\":\"was not\",\"we'd\":\"we had\",\"we'd've\":\"we would have\",\"we'll\":\"we will\",\"we're\":\"we are\",\\\n",
        "\"we've\":\"we have\",\"weren't\":\"were not\",\"what'd\":\"what did\",\"what'll\":\"what will\",\"what're\":\"what are\",\"what's\":\"what is\",\\\n",
        "\"what've\":\"what have\",\"when's\":\"when is\",\"where'd\":\"where did\",\"where're\":\"where are\",\"where've\":\"where have\",\\\n",
        "\"which's\":\"which has\",\"who'd\":\"who would\",\"who'd've\":\"who would have\",\"who'll\":\"who shall\",\"who're\":\"who are\",\\\n",
        "\"who's\":\"who has\",\"who've\":\"who have\",\"why'd\":\"why did\",\"why're\":\"why are\",\"why's\":\"why has\",\"won't\":\"will not\",\\\n",
        "\"would've\":\"would have\",\"wouldn't\":\"would not\",\"y'all\":\"you all\",\"you'd\":\"you had\",\"you'll\":\"you shall\",\"you're\":\"you are\",\\\n",
        "\"you've\":\"you have\"})\n",
        "##############Lets do the same for summary Text##################################\n",
        "data['Summary'] = data['Summary'].replace({\"ain't\":\"am not\",\"amn't\":\"am not\",\"aren't\":\"are not\", \\\n",
        "\"can't\":\"cannot\",\"cause\":\"because\",\"could've\":\"could have\",\"couldn't\":\"could not\",\"couldn't've\":\"could not have\", \\\n",
        "\"daren't\":\"dare not\",\"daresn't\":\"dare not\",\"dasn't\":\"dare not\",\"didn't\":\"did not\",\"doesn't\":\"does not\", \\\n",
        "\"don't\":\"do not\",\"e'er\":\"ever\",\"everyone's\":\"everyone is\",\"finna\":\"fixing to\",\"gimme\":\"give me\", \\\n",
        "\"gonna\":\"going to\",\"gon't\":\"go not\",\"gotta\":\"got to\",\"hadn't\":\"had not\",\"hasn't\":\"has not\",\"haven't\":\"have not\",\\\n",
        "\"he'd\":\"he had\",\"he'll\":\"he shall\",\"he's\":\"he has\",\"he've\":\"he have\",\"how'd\":\"how did\",\"how'll\":\"how will\",\\\n",
        "\"how're\":\"how are\",\"how's\":\"how has\",\"I'd\":\"I had\",\"I'll\":\"I shall\",\"I'm\":\"I am\",\"I'm'a\":\"I am about to\",\\\n",
        "\"I'm'o\":\"I am going to\",\"I've\":\"I have\",\"isn't\":\"is not\",\"it'd\":\"it would\",\"it'll\":\"it shall\",\"it's\":\"it has\",\\\n",
        "\"let's\":\"let us\",\"mayn't\":\"may not\",\"may've\":\"may have\",\"mightn't\":\"might not\",\"might've\":\"might have\",\\\n",
        "\"mustn't\":\"must not\",\"mustn't've\":\"must not have\",\"must've\":\"must have\",\"needn't\":\"need not\",\"ne'er\":\"never\",\\\n",
        "\"o'clock\":\"of the clock\",\"o'er\":\"\",\"ol'\":\"old\",\"oughtn't\":\"ought not\",\"shalln't\":\"shall not\",\"shan't\":\"shall not\",\\\n",
        "\"she'd\":\"she had\",\"she'll\":\"she shall\",\"she's\":\"she is\",\"should've\":\"should have\",\"shouldn't\":\"should not\",\\\n",
        "\"shouldn't've\":\"should not have\",\"somebody's\":\"somebody has\",\"someone's\":\"someone has\",\"something's\":\"something has\",\\\n",
        "\"that'll\":\"that will\",\"that're\":\"that are\",\"that's\":\"that is\",\"that'd\":\"that would\",\"there'd\":\"there had\",\\\n",
        "\"there'll\":\"there shall\",\"there're\":\"there are\",\"there's\":\"there is\",\"these're\":\"hese are\",\"they'd\":\"they had\",\\\n",
        "\"they'll\":\"they will\",\"they're\":\"they are\",\"they've\":\"they have\",\"this's\":\"\",\"those're\":\"those are\",\"tis\":\"it is\",\\\n",
        "\"twas\":\"it was\",\"wasn't\":\"was not\",\"we'd\":\"we had\",\"we'd've\":\"we would have\",\"we'll\":\"we will\",\"we're\":\"we are\",\\\n",
        "\"we've\":\"we have\",\"weren't\":\"were not\",\"what'd\":\"what did\",\"what'll\":\"what will\",\"what're\":\"what are\",\"what's\":\"what is\",\\\n",
        "\"what've\":\"what have\",\"when's\":\"when is\",\"where'd\":\"where did\",\"where're\":\"where are\",\"where've\":\"where have\",\\\n",
        "\"which's\":\"which has\",\"who'd\":\"who would\",\"who'd've\":\"who would have\",\"who'll\":\"who shall\",\"who're\":\"who are\",\\\n",
        "\"who's\":\"who has\",\"who've\":\"who have\",\"why'd\":\"why did\",\"why're\":\"why are\",\"why's\":\"why has\",\"won't\":\"will not\",\\\n",
        "\"would've\":\"would have\",\"wouldn't\":\"would not\",\"y'all\":\"you all\",\"you'd\":\"you had\",\"you'll\":\"you shall\",\"you're\":\"you are\",\\\n",
        "\"you've\":\"you have\"})\n",
        "########################################################################################\n",
        "# iii) Remove Special Characters except alpahbets and numbers\n",
        "#The reason i dont want to remove number people might write got five eggs as 5 eggs or vice versa and dont want to lose \n",
        "#that information which could be useful\n",
        "#Ref:https://stackoverflow.com/questions/33257344/how-to-remove-special-characers-from-a-column-of-dataframe-using-module-re\n",
        "data[\"Text\"]=data[\"Text\"].map(lambda x: re.sub(r'[^a-zA-Z ]', '', x))\n",
        "data[\"Summary_copy\"]=data[\"Summary\"].map(lambda x: re.sub(r'[^a-zA-Z ]', '', x))\n",
        "import nltk\n",
        "nltk.download(\"popular\")\n",
        "\n",
        "#The Summary are usually so small if we remove few stopwords the meaning itself would be complely lost or chamge\n",
        "# So let us see what all stopwords we have\n",
        "#Ref:::::::::https://stackoverflow.com/questions/5511708/adding-words-to-nltk-stoplist\n",
        "#https://chrisalbon.com/machine_learning/preprocessing_text/remove_stop_words/\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "newStopWords = ['would','could','br','<br>','<','>','-','---br', '-----br','------br','-------j','', '-', '--', '---', '----', '-----', '------', '-------', '---------', '-------------------------', '----------------------------------------------------------------------------------------------------------------------------br', '------------------------------------------------------------------------------------------------------br', '---------------------------------------------------------------------------------------------------br', '-----------------------------------------------------------------------------------br', '--------------------------------------------------------------------------------br', '-------------------------------------------------------------------------------br', '--------------------------------------------------------------------------br', '-------------------------------------------------------------------------br', '---------------------------------------------------------------------br', '-------------------------------------------------------------------br', '-----------------------------------------------------------------br', '---------------------------------------------------------------br', '--------------------------------------------------------------br', '-------------------------------------------------------------br', '------------------------------------------------------------br', '-----------------------------------------------------------br', '---------------------------------------------------------br', '------------------------------------------------------br', '--------------------------------------------------br', '------------------------------------------------br', '-----------------------------------------------br', '---------------------------------------------br', '-------------------------------------------br', '------------------------------------------br', '---------------------------------------br', '-------------------------------------br', '-----------------------------------br', '---------------------------------br', '--------------------------------br', '-------------------------------br', '----------------------------br', '---------------------------br', '--------------------------br', '-------------------------br', '-----------------------br', '----------------------br', '---------------------br', '--------------------br', '--------------------old', '-------------------br', '-------------------update', '------------------br', '-----------------br', '----------------br', '----------------powdered--------wheatgrass', '---------------br', '--------------br', '-------------br', '------------br', '-----------br', '----------850mg--------------550mg------br', '----------br', '---------br', '---------j', '--------br', '-------br', '-------excelent', '-------j', '-------this', '------br', '------open', '-----br']\n",
        "#newStopWords = ['would','could','br','<br>','<','>','-','---br', '-----br','------br','-------j','']\n",
        "notstopwords = ['not','no','nor']\n",
        "stopwords.extend(newStopWords)\n",
        "stopwords = [word for word in stopwords if word not in notstopwords]\n",
        "\n",
        "#  iv) For now let us just go with flow will use default stopwords as creating our own stop words is very time consuming\n",
        "#Rather will use n-gram stratergy to get rid of problem of stopwords removal changing the meaning of sentences\n",
        "#Ref:https://stackoverflow.com/questions/43184364/python-remove-stop-words-from-pandas-dataframe-give-wrong-output\n",
        "data[\"New_Text\"]= data['Text'].apply(lambda x: [item for item in str.split(x) if item not in stopwords])\n",
        "data[\"Summary\"]= data['Summary'].apply(lambda x: [item for item in str.split(x) if item not in stopwords])\n",
        "\n",
        "#Ref:https://stackoverflow.com/questions/37347725/converting-a-panda-df-list-into-a-string/37347837\n",
        "#we are creating new column New_summary so in case in future we need summary it is intact\n",
        "data[\"New_Text\"]=data[\"New_Text\"].apply(' '.join)\n",
        "data[\"Summary\"]=data[\"Summary\"].apply(' '.join)\n",
        "\n",
        "# v) Now lets do Stemming\n",
        "#https://stackoverflow.com/questions/48617589/beginner-stemming-in-pandas-produces-letters-not-stems\n",
        "english_stemmer=SnowballStemmer('english', ignore_stopwords=True)\n",
        "data[\"New_Text\"] = data[\"New_Text\"].apply(english_stemmer.stem)\n",
        "data[\"Summary\"] = data[\"Summary\"].apply(english_stemmer.stem)\n",
        "data[\"New_Text\"] = data[\"New_Text\"].astype(str)\n",
        "data[\"Summary\"] = data[\"Summary\"].astype(str)\n",
        "\n",
        "#vi) stemming without removing stop words\n",
        "english_stemmer=SnowballStemmer('english', ignore_stopwords=True)\n",
        "#https://stackoverflow.com/questions/34724246/attributeerror-float-object-has-no-attribute-lower\n",
        "data[\"Text_with_stop\"]=data[\"Text\"].astype(str)\n",
        "data[\"Summary\"]=data[\"Summary\"].astype(str)\n",
        "data[\"Text_with_stop\"]=data[\"Text_with_stop\"].str.lower().map(english_stemmer.stem)\n",
        "data[\"Summary\"]=data[\"Summary\"].str.lower().map(english_stemmer.stem)\n",
        "data[\"Text_with_stop\"]=data[\"Text_with_stop\"].apply(''.join)\n",
        "data[\"Summary\"]=data[\"Summary\"].apply(''.join)\n",
        "data[\"Text_with_stop\"] = data[\"Text_with_stop\"].astype(str)\n",
        "data[\"Summary\"] = data[\"Summary\"].astype(str)\n",
        "################\n",
        "# New_text_without_stop_convert as string\n",
        "data[\"New_Text\"] = data[\"New_Text\"].astype(str)\n",
        "data[\"New_Text\"]=data[\"New_Text\"].apply(''.join)\n",
        "data[\"Summary\"]=data[\"Summary\"].apply(''.join)\n",
        "data[\"Summary\"] = data[\"Summary\"].astype(str)\n",
        "data[\"New_Text\"] = data[\"New_Text\"].astype(str)\n",
        "print(data[\"Score\"].value_counts())\n",
        "print (\"Thus we see there are 85% and 15% positive and negative reviews,thus a unbalanced dataset.So to create a balanced \\\n",
        "dataset we first copy negative dataset 6 times than we sample with same number of times as positive\")\n",
        "# Let include another feature which is the length of the text \n",
        "data_neg = data[data[\"Score\"] == 0]\n",
        "data_pos = data[data[\"Score\"] == 1]\n",
        "data = pd.concat([data_pos,data_neg])\n",
        "#https://stackoverflow.com/questions/46429033/how-do-i-count-the-total-number-of-words-in-a-pandas-dataframe-cell-and-add-thos\n",
        "data[\"Text_length\"]= (data[\"New_Text\"].str.count(' ') + 1)\n",
        "data[\"Summary_length\"]= (data[\"Summary\"].str.count(' ') + 1)\n",
        "data[\"Time_formatted\"]= pd.to_datetime(data[\"Time\"])\n",
        "data.sort_values(by=['Time_formatted'], inplace=True)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of data points available\n",
            "(525814, 10)\n",
            "Number of data points after removing duplicates\n",
            "(366392, 10)\n",
            "Number of data points after removing where HelpfulnessNumerator is more than HelpfulnessDenominator \n",
            "(366390, 10)\n",
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n",
            "1    308679\n",
            "0     57711\n",
            "Name: Score, dtype: int64\n",
            "Thus we see there are 85% and 15% positive and negative reviews,thus a unbalanced dataset.So to create a balanced dataset we first copy negative dataset 6 times than we sample with same number of times as positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DwsTJlwDLAe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c807f58d-9cea-44de-8d2f-999e0b2c2169"
      },
      "source": [
        "print (data)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Id   ProductId  ... Summary_length                Time_formatted\n",
            "138706  150524  0006641040  ...              3 1970-01-01 00:00:00.939340800\n",
            "138683  150501  0006641040  ...              7 1970-01-01 00:00:00.940809600\n",
            "417839  451856  B00004CXX9  ...              2 1970-01-01 00:00:00.944092800\n",
            "212472  230285  B00004RYGX  ...              4 1970-01-01 00:00:00.944438400\n",
            "417838  451855  B00004CXX9  ...              1 1970-01-01 00:00:00.946857600\n",
            "...        ...         ...  ...            ...                           ...\n",
            "478157  517064  B007OYUZIM  ...              1 1970-01-01 00:00:01.351209600\n",
            "457460  494625  B0012VSXIM  ...              5 1970-01-01 00:00:01.351209600\n",
            "42269    45991  B007VQQT1K  ...              3 1970-01-01 00:00:01.351209600\n",
            "15069    16426  B007TJGZ54  ...              2 1970-01-01 00:00:01.351209600\n",
            "479033  518008  B00529PFX6  ...              1 1970-01-01 00:00:01.351209600\n",
            "\n",
            "[366390 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeZzy4-fCFi_",
        "colab_type": "text"
      },
      "source": [
        "So we see we have 16 rows few of them are copy. The eason we made copy so in case we need to use them in future incase our data gets corrupted due to some of our mistakes. But for now everything looks good. Lets make another dataframe with just 12 columns leaving copies and now we can operate on this new dataframe "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emC85kS0ECTg",
        "colab_type": "text"
      },
      "source": [
        "Also as number of rows is almost 3.5 lakhs which is taking us too long to compute lets us just take last 1.5 lakh rows to work on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC20JhzUEOdn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7017cc74-5cd4-4615-dd00-7064d74790d0"
      },
      "source": [
        "#data.sort_values(by=['Time_formatted'], inplace=True)\n",
        "data = data.tail(150000)\n",
        "print (data)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Id   ProductId  ... Summary_length                Time_formatted\n",
            "57121    61959  B000CQG8K8  ...              3 1970-01-01 00:00:01.320451200\n",
            "503701  544672  B001P3PR54  ...              3 1970-01-01 00:00:01.320451200\n",
            "144439  156703  B002L35LH6  ...              3 1970-01-01 00:00:01.320451200\n",
            "100504  109185  B003SE8CN2  ...              5 1970-01-01 00:00:01.320451200\n",
            "128467  139421  B000EM8308  ...              1 1970-01-01 00:00:01.320451200\n",
            "...        ...         ...  ...            ...                           ...\n",
            "478157  517064  B007OYUZIM  ...              1 1970-01-01 00:00:01.351209600\n",
            "457460  494625  B0012VSXIM  ...              5 1970-01-01 00:00:01.351209600\n",
            "42269    45991  B007VQQT1K  ...              3 1970-01-01 00:00:01.351209600\n",
            "15069    16426  B007TJGZ54  ...              2 1970-01-01 00:00:01.351209600\n",
            "479033  518008  B00529PFX6  ...              1 1970-01-01 00:00:01.351209600\n",
            "\n",
            "[150000 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKt4a0X0CEr6",
        "colab_type": "code",
        "outputId": "139fdfe6-431a-41ff-8a6b-c211722ec878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "#data.sort_values(by=['Time_formatted'], inplace=True)\n",
        "data_text= data['New_Text']\n",
        "#data.sort_values(by=['Time_formatted'], inplace=True)\n",
        "data_summary= data['Summary_copy']\n",
        "#data.sort_values(by=['Time_formatted'], inplace=True)\n",
        "new_data_x = data[['Id','ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Score','Summary_copy','New_Text','Text_length','Summary_length','Time_formatted']]\n",
        "new_data_y = data[['Score']]\n",
        "data_text_summary = pd.concat([data_summary, data_text], axis=1, ignore_index=True)\n",
        "data_text_summary.columns = [\"Summary\", \"Text\"]\n",
        "print (\"############################\")\n",
        "print ((data_text_summary))\n",
        "merged_data_text_summary = pd.DataFrame()\n",
        "merged_data_text_summary['Summary_Text'] = data_text_summary[['Summary', 'Text']].apply(lambda x: ' '.join(x), axis = 1)\n",
        "print (\"############################\")\n",
        "print ((merged_data_text_summary))\n",
        "#X= new_data_x.values"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############################\n",
            "                                Summary                                               Text\n",
            "57121            wonderful aromatic tea  tea wonderful treat cold night cinnamon aroma ...\n",
            "503701          great treat for my dogs  one best products market cleaning dogs teeth o...\n",
            "144439                 yummy lil things  not potato chip tortia chip seaweed paper form...\n",
            "100504  its a hit   stopped smelly poop  product definitely hit two finicky cats one ye...\n",
            "128467                             yuck  bought pregnant terrible morning sickness thin...\n",
            "...                                 ...                                                ...\n",
            "478157                         just bad  watery unpleasant like yoohoo mixed dirty dish...\n",
            "457460      good  plenty licorice candy  like licorice love candy remember eating candy...\n",
            "42269                   great irish tea  recently returned wonderful three week excursi...\n",
            "15069                      super coffee  great coffee easy brew coffee great aroma good...\n",
            "479033                        expensive  expensive tough salty tried piece not care muc...\n",
            "\n",
            "[150000 rows x 2 columns]\n",
            "############################\n",
            "                                             Summary_Text\n",
            "57121   wonderful aromatic tea tea wonderful treat col...\n",
            "503701  great treat for my dogs one best products mark...\n",
            "144439  yummy lil things not potato chip tortia chip s...\n",
            "100504  its a hit   stopped smelly poop product defini...\n",
            "128467  yuck bought pregnant terrible morning sickness...\n",
            "...                                                   ...\n",
            "478157  just bad watery unpleasant like yoohoo mixed d...\n",
            "457460  good  plenty licorice candy like licorice love...\n",
            "42269   great irish tea recently returned wonderful th...\n",
            "15069   super coffee great coffee easy brew coffee gre...\n",
            "479033  expensive expensive tough salty tried piece no...\n",
            "\n",
            "[150000 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsFYDUBnMr-X",
        "colab_type": "code",
        "outputId": "24b34c5c-3a84-4e1d-ed70-0f2ecc7da7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "data_text_summary_train,data_text_summary_test = train_test_split(merged_data_text_summary, test_size=0.33, shuffle=False)\n",
        "print (data_text_summary_train)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             Summary_Text\n",
            "57121   wonderful aromatic tea tea wonderful treat col...\n",
            "503701  great treat for my dogs one best products mark...\n",
            "144439  yummy lil things not potato chip tortia chip s...\n",
            "100504  its a hit   stopped smelly poop product defini...\n",
            "128467  yuck bought pregnant terrible morning sickness...\n",
            "...                                                   ...\n",
            "88548   fantastic buy exact product large oriental mar...\n",
            "15067   coffee flavored water excited see pack coffee ...\n",
            "110968  too sweet and too artificial not impressed pro...\n",
            "15033   very bland and weak coffee admit like strong f...\n",
            "425885  sweet with a kick candies sweet chewy mean kic...\n",
            "\n",
            "[100500 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avzjQkKGMVfW",
        "colab_type": "code",
        "outputId": "77cb132f-d516-4319-f54d-077d0e5eba66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "Y = new_data_y['Score'].values\n",
        "\n",
        "y_train,y_test = train_test_split(Y, test_size=0.33, shuffle=False)\n",
        "print ((y_train).shape)\n",
        "print ((y_test).shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100500,)\n",
            "(49500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQCU2n8G-iPV",
        "colab_type": "code",
        "outputId": "bc4e45c9-8f97-401f-be3d-096621d3fefa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "data_text_summary_train_val = data_text_summary_train.values\n",
        "data_text_summary_test_val = data_text_summary_test.values\n",
        "\n",
        "\n",
        "print (type(data_text_summary_train_val))\n",
        "print (\"Shape of data_text_summary_train is::\")\n",
        "\n",
        "print (data_text_summary_train_val.shape)\n",
        "print (\"First few row of data_text_summary_train looks like::\")\n",
        "\n",
        "print (data_text_summary_train_val)\n",
        "print (\"###########################################################\")\n",
        "print (type(data_text_summary_train_val.ravel()))\n",
        "print (\"###########################################################\")\n",
        "print (data_text_summary_train_val.ravel().shape)\n",
        "print (\"###########################################################\")\n",
        "print (type(data_text_summary_train['Summary_Text'].astype(str).values.shape))\n",
        "print (\"###########################################################\")\n",
        "#print (type(data_text_summary_train_val_xml))\n",
        "print (\"###########################################################\")\n",
        "#print ((data_text_summary_train_val_xml))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "Shape of data_text_summary_train is::\n",
            "(100500, 1)\n",
            "First few row of data_text_summary_train looks like::\n",
            "[['wonderful aromatic tea tea wonderful treat cold night cinnamon aroma enticing buying years amazon always best pric']\n",
            " ['great treat for my dogs one best products market cleaning dogs teeth opinion like give treat day clean teeth noticed difference week']\n",
            " ['yummy lil things not potato chip tortia chip seaweed paper formbr please dont create bad review thinking something lunchbr seaweed paper form meant soup miso soup quick appetite supresant please give bad reviews items didnt research things dont understand']\n",
            " ...\n",
            " ['too sweet and too artificial not impressed product fact sitting pantry might possible brew cup strong coffee divide two run cappuccino add flavor']\n",
            " ['very bland and weak coffee admit like strong flavorful not burnt tasting coffee give four stars tully house blend breakfast blend quite weakbr ordering fifty husband desperation trying use putting kcup espresso setting using kcups expresso needed fill coffee cup im sure fine kcup like weak coffe']\n",
            " ['sweet with a kick candies sweet chewy mean kick towards end think helped little morning sickness keep using se']]\n",
            "###########################################################\n",
            "<class 'numpy.ndarray'>\n",
            "###########################################################\n",
            "(100500,)\n",
            "###########################################################\n",
            "<class 'tuple'>\n",
            "###########################################################\n",
            "###########################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbnbcT79QmgH",
        "colab_type": "text"
      },
      "source": [
        "https://machinelearningmastery.com/prepare-text-data-deep-learning-keras/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qj5qb3EhYeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "# create the tokenizer\n",
        "t1 = Tokenizer(num_words=5000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
        "t1.fit_on_texts(data_text_summary_train['Summary_Text'].astype(str).values)\n",
        "\n",
        "# summarize what was learned\n",
        "t1_word_count = (t1.word_counts)\n",
        "t1_document_count = (t1.document_count)\n",
        "t1_word_index = (t1.word_index)\n",
        "t1_word_docs=(t1.word_docs)\n",
        "\n",
        "text_to_seq_train = t1.texts_to_sequences(data_text_summary_train['Summary_Text'].astype(str).values)\n",
        "text_to_seq_test = t1.texts_to_sequences(data_text_summary_test['Summary_Text'].astype(str).values)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm0Tik1pyrVP",
        "colab_type": "code",
        "outputId": "94130fba-97e5-4bb3-9114-8ff08c5c6526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print (list(t1_word_count.items())[:100])\n",
        "print ((t1_document_count))\n",
        "print (list(t1_word_index.items())[:150])\n",
        "print (list(t1_word_docs.items())[:500])\n",
        "print (\"##################\")\n",
        "print ((text_to_seq_train[:1]))\n",
        "print (text_to_seq_test[:1])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('wonderful', 5025), ('aromatic', 210), ('tea', 24812), ('treat', 5140), ('cold', 2368), ('night', 1576), ('cinnamon', 2694), ('aroma', 1611), ('enticing', 43), ('buying', 4900), ('years', 6501), ('amazon', 14079), ('always', 6574), ('best', 18375), ('pric', 1088), ('great', 42261), ('for', 6797), ('my', 4676), ('dogs', 6541), ('one', 30522), ('products', 5315), ('market', 2106), ('cleaning', 303), ('teeth', 1565), ('opinion', 1227), ('like', 45706), ('give', 7327), ('day', 8131), ('clean', 1779), ('noticed', 1543), ('difference', 2065), ('week', 2296), ('yummy', 3602), ('lil', 88), ('things', 3589), ('not', 63868), ('potato', 1348), ('chip', 947), ('tortia', 1), ('seaweed', 246), ('paper', 805), ('formbr', 19), ('please', 1440), ('dont', 17379), ('create', 310), ('bad', 6073), ('review', 3555), ('thinking', 987), ('something', 6796), ('lunchbr', 33), ('form', 791), ('meant', 312), ('soup', 3055), ('miso', 260), ('quick', 2639), ('appetite', 220), ('supresant', 1), ('reviews', 3716), ('items', 1393), ('didnt', 6699), ('research', 871), ('understand', 727), ('its', 910), ('a', 6940), ('hit', 1215), ('stopped', 1114), ('smelly', 120), ('poop', 273), ('product', 31762), ('definitely', 5740), ('two', 8514), ('finicky', 260), ('cats', 4071), ('old', 5616), ('trying', 3823), ('find', 13325), ('natural', 4909), ('yet', 2440), ('affordable', 471), ('wet', 830), ('cat', 5306), ('food', 20220), ('boys', 217), ('feces', 26), ('carrying', 619), ('potent', 197), ('odor', 425), ('read', 2644), ('many', 7634), ('sites', 119), ('suggested', 464), ('better', 12432), ('digestive', 477), ('system', 654), ('ultimately', 70), ('fecal', 14), ('use', 16265), ('litter', 683), ('without', 6653), ('perfumes', 12)]\n",
            "100500\n",
            "[('not', 1), ('like', 2), ('good', 3), ('great', 4), ('taste', 5), ('product', 6), ('one', 7), ('coffee', 8), ('flavor', 9), ('love', 10), ('tea', 11), ('food', 12), ('no', 13), ('get', 14), ('really', 15), ('best', 16), ('dont', 17), ('much', 18), ('use', 19), ('little', 20), ('buy', 21), ('also', 22), ('time', 23), ('price', 24), ('amazon', 25), ('im', 26), ('make', 27), ('even', 28), ('find', 29), ('ive', 30), ('tried', 31), ('well', 32), ('chocolate', 33), ('better', 34), ('water', 35), ('try', 36), ('first', 37), ('eat', 38), ('delicious', 39), ('drink', 40), ('dog', 41), ('sweet', 42), ('sugar', 43), ('used', 44), ('made', 45), ('bag', 46), ('found', 47), ('tastes', 48), ('bought', 49), ('box', 50), ('way', 51), ('the', 52), ('nice', 53), ('recommend', 54), ('cup', 55), ('two', 56), ('stuff', 57), ('think', 58), ('go', 59), ('day', 60), ('since', 61), ('hot', 62), ('mix', 63), ('got', 64), ('bit', 65), ('store', 66), ('favorite', 67), ('still', 68), ('know', 69), ('order', 70), ('many', 71), ('ever', 72), ('cant', 73), ('give', 74), ('perfect', 75), ('never', 76), ('free', 77), ('add', 78), ('quality', 79), ('want', 80), ('a', 81), ('brand', 82), ('milk', 83), ('for', 84), ('something', 85), ('say', 86), ('flavors', 87), ('didnt', 88), ('every', 89), ('makes', 90), ('without', 91), ('right', 92), ('always', 93), ('lot', 94), ('and', 95), ('dogs', 96), ('healthy', 97), ('years', 98), ('loves', 99), ('less', 100), ('different', 101), ('fresh', 102), ('oil', 103), ('easy', 104), ('doesnt', 105), ('small', 106), ('back', 107), ('ordered', 108), ('tasty', 109), ('excellent', 110), ('bad', 111), ('using', 112), ('put', 113), ('organic', 114), ('enough', 115), ('snack', 116), ('long', 117), ('pack', 118), ('definitely', 119), ('sure', 120), ('keep', 121), ('need', 122), ('ingredients', 123), ('pretty', 124), ('old', 125), ('hard', 126), ('whole', 127), ('enjoy', 128), ('green', 129), ('see', 130), ('sauce', 131), ('strong', 132), ('happy', 133), ('products', 134), ('cat', 135), ('however', 136), ('thought', 137), ('new', 138), ('work', 139), ('though', 140), ('far', 141), ('coconut', 142), ('treat', 143), ('thing', 144), ('looking', 145), ('high', 146), ('eating', 147), ('local', 148), ('big', 149), ('wonderful', 150)]\n",
            "[('night', 1398), ('always', 5901), ('aroma', 1417), ('wonderful', 4525), ('enticing', 42), ('aromatic', 201), ('buying', 4554), ('amazon', 11510), ('tea', 8775), ('best', 14611), ('pric', 1088), ('treat', 4087), ('years', 5728), ('cold', 2000), ('cinnamon', 1594), ('cleaning', 281), ('great', 30760), ('products', 4384), ('one', 22327), ('teeth', 1197), ('market', 1921), ('day', 6814), ('difference', 1851), ('clean', 1561), ('my', 4631), ('week', 2125), ('opinion', 1174), ('for', 6672), ('dogs', 3631), ('give', 6566), ('noticed', 1416), ('like', 30701), ('something', 6000), ('dont', 14309), ('yummy', 3219), ('please', 1296), ('didnt', 5794), ('thinking', 962), ('review', 3164), ('tortia', 1), ('supresant', 1), ('miso', 114), ('formbr', 19), ('bad', 5185), ('potato', 959), ('meant', 297), ('soup', 1587), ('paper', 655), ('reviews', 3301), ('seaweed', 156), ('quick', 2421), ('research', 791), ('lil', 78), ('understand', 710), ('create', 296), ('lunchbr', 33), ('not', 39188), ('items', 1205), ('chip', 754), ('appetite', 185), ('things', 3250), ('form', 707), ('find', 11453), ('petsmart', 125), ('system', 598), ('save', 2649), ('beat', 852), ('book', 354), ('eating', 4418), ('savings', 207), ('significantly', 199), ('affordable', 448), ('cans', 1496), ('trying', 3624), ('many', 6672), ('full', 3261), ('definitely', 5331), ('hit', 1160), ('ultimately', 69), ('litter', 259), ('free', 5207), ('suggested', 444), ('older', 512), ('least', 2778), ('favs', 21), ('cats', 1998), ('stopped', 1054), ('moist', 809), ('two', 7228), ('commercialized', 4), ('its', 880), ('poop', 195), ('boy', 490), ('needing', 123), ('better', 10616), ('digestive', 410), ('much', 14069), ('may', 3715), ('juice', 1615), ('box', 6685), ('smelly', 113), ('even', 11498), ('gravy', 314), ('odor', 330), ('use', 12557), ('notice', 926), ('portions', 217), ('fecal', 13), ('try', 10295), ('plusbr', 34), ('want', 6147), ('stay', 1087), ('petco', 131), ('food', 10134), ('case', 2349), ('helped', 652), ('commit', 34), ('doesnt', 5577), ('feces', 24), ('luck', 385), ('stores', 3336), ('per', 3469), ('make', 11383), ('product', 22363), ('sure', 5284), ('carrying', 598), ('drink', 7238), ('highly', 4343), ('finicky', 237), ('super', 2128), ('sop', 8), ('deal', 2551), ('wet', 654), ('get', 16147), ('eat', 8741), ('purchased', 4084), ('deorderizers', 1), ('say', 6131), ('single', 1417), ('flavors', 5296), ('yet', 2303), ('portion', 606), ('sites', 114), ('old', 4690), ('potent', 181), ('brand', 5589), ('perfumes', 12), ('watery', 395), ('good', 30795), ('natural', 3739), ('boys', 190), ('achieve', 71), ('goal', 63), ('pricesbr', 20), ('found', 8636), ('also', 12858), ('hungry', 441), ('see', 4864), ('havent', 1932), ('read', 2421), ('subscribe', 1572), ('recommend', 8645), ('pet', 1149), ('waterbr', 301), ('anyone', 2147), ('a', 6610), ('cat', 2348), ('reduced', 304), ('new', 4388), ('without', 6059), ('spicy', 1699), ('terrible', 1109), ('actually', 4451), ('trash', 322), ('take', 4288), ('mouth', 1913), ('rather', 2056), ('getting', 3489), ('morning', 2905), ('went', 2719), ('yuck', 422), ('candy', 2964), ('sickness', 78), ('pregnant', 109), ('wrong', 1642), ('put', 5235), ('bought', 8662), ('call', 954), ('wash', 364), ('washing', 118), ('looking', 4697), ('steam', 139), ('brezza', 52), ('maker', 935), ('already', 1619), ('makes', 6173), ('pricey', 1040), ('well', 11163), ('container', 1715), ('stuff', 6874), ('bulk', 1285), ('mine', 1332), ('issue', 951), ('puree', 181), ('convenient', 1471), ('no', 15438), ('strong', 4359), ('intent', 21), ('process', 649), ('add', 5671), ('know', 6801), ('baby', 1618), ('freeze', 414), ('holds', 376), ('hand', 1571), ('babysit', 7), ('processor', 73), ('love', 20666), ('fresh', 5416), ('tried', 11219), ('loves', 5352), ('big', 4562), ('anyway', 1207), ('decided', 2698), ('come', 3267), ('ingredients', 4312), ('breeze', 65), ('homemade', 921), ('dishwasher', 46), ('way', 8218), ('easy', 5470), ('overtim', 1), ('small', 5310), ('away', 3373), ('making', 3258), ('walk', 256), ('parts', 270), ('used', 8892), ('couple', 2561), ('weeks', 1618), ('look', 3135), ('completely', 1472), ('oz', 3096), ('baking', 1171), ('locally', 913), ('machine', 1333), ('red', 2015), ('wouldnt', 1911), ('price', 11393), ('people', 3872), ('bread', 1577), ('think', 7372), ('himher', 10), ('close', 1545), ('yeast', 334), ('star', 1859), ('package', 3979), ('money', 3299), ('said', 3475), ('hesitate', 216), ('jarsbr', 15), ('alone', 689), ('to', 3728), ('another', 4468), ('excessive', 126), ('knocked', 62), ('lot', 5818), ('reviewer', 779), ('ive', 10524), ('ord', 1136), ('store', 6871), ('final', 205), ('just', 1219), ('pound', 1183), ('cheaper', 2441), ('smart', 226), ('it', 4699), ('rating', 522), ('starbucks', 1253), ('their', 112), ('expire', 107), ('often', 1737), ('days', 3201), ('todaybr', 30), ('cool', 728), ('soonbr', 31), ('buy', 13474), ('bugs', 120), ('expiration', 643), ('are', 1206), ('groceries', 101), ('yesterday', 328), ('date', 1179), ('got', 7048), ('pods', 720), ('coffee', 11773), ('cap', 293), ('bottle', 3138), ('dome', 11), ('travelling', 25), ('namebut', 1), ('mainly', 256), ('atleast', 24), ('attractive', 184), ('lookleakages', 1), ('fit', 829), ('bcoz', 2), ('expect', 1411), ('woulkd', 1), ('galore', 18), ('looked', 1606), ('moreone', 1), ('fooled', 131), ('course', 1661), ('dosenti', 1), ('bottles', 1377), ('be', 807), ('bag', 7052), ('kind', 2990), ('pieces', 1811), ('chewy', 1201), ('expensive', 3689), ('bitohoney', 4), ('topeanuty', 1), ('and', 6417), ('worth', 4414), ('taste', 22870), ('morningbr', 64), ('the', 8632), ('english', 484), ('breakfast', 2130), ('every', 6059), ('twinings', 166), ('favoritebr', 82), ('nighttim', 1), ('nice', 7526), ('expressions', 10), ('latte', 397), ('mess', 898), ('dinner', 1011), ('flavor', 19459), ('caffeine', 1328), ('answer', 219), ('decaf', 1122), ('enjoy', 4873), ('espresso', 896), ('told', 1147), ('withi', 2), ('organic', 3834), ('wound', 77), ('have', 844), ('hole', 220), ('sandwich', 440), ('size', 3861), ('bothering', 17), ('production', 188), ('sandwiches', 356), ('experience', 1457), ('health', 2627), ('breads', 191), ('tasty', 5383), ('productionbatch', 1), ('emailed', 125), ('farmers', 91), ('poor', 790), ('tell', 1959), ('darn', 248), ('bonus', 444), ('truly', 1098), ('go', 7448), ('piece', 974), ('ball', 298), ('utterly', 71), ('berkeley', 10), ('neighbor', 94), ('udis', 50), ('gf', 474), ('air', 624), ('problem', 2878), ('can', 640), ('rest', 1331), ('i', 3679), ('mailed', 53), ('bionaturae', 16), ('againbr', 356), ('little', 12604), ('loafseveral', 1), ('coupon', 128), ('live', 1462), ('simple', 1188), ('etc', 1775), ('correctedno', 1), ('udiswow', 1), ('loaf', 177), ('markets', 179), ('flavorbr', 562), ('gluten', 2224), ('simply', 1749), ('based', 1186), ('middle', 478), ('giant', 180), ('opposite', 90), ('bubble', 289), ('pretty', 4927), ('crumble', 147), ('loafbr', 6), ('pastasbut', 1), ('thats', 3620), ('mushy', 322), ('never', 6564), ('bin', 81), ('rice', 2468), ('again', 298), ('happening', 68), ('daybr', 253), ('life', 1601), ('service', 1388), ('theyd', 239), ('near', 821), ('compost', 83), ('pasta', 1274), ('cant', 6991), ('loaves', 75), ('thanks', 1410), ('info', 284), ('mentioned', 648), ('texture', 3459), ('crust', 270), ('golf', 28), ('depressing', 12), ('intolerance', 71), ('sometimes', 1821), ('unless', 1084), ('might', 3172), ('quality', 5786), ('nutritional', 774), ('worry', 609), ('ask', 701), ('order', 6590), ('hey', 272), ('shipping', 3528), ('dad', 261), ('youre', 2785), ('heard', 833), ('im', 11258), ('copy', 47), ('dads', 36), ('teenager', 37), ('sense', 431), ('christmas', 1685), ('let', 2358), ('okay', 808), ('d', 394), ('around', 3858), ('though', 4767), ('knowbr', 69), ('dollar', 415), ('placesdollar', 1), ('came', 3966), ('birthday', 573), ('else', 2031), ('afford', 287), ('plastic', 1845), ('cause', 760), ('excellent', 5322), ('ones', 2594), ('bitomoney', 1), ('haha', 81), ('hard', 4985), ('sold', 1296), ('butsince', 1), ('original', 1431), ('loved', 3686), ('easily', 1783), ('facts', 172), ('someplace', 19), ('since', 7210), ('everyone', 1826), ('caffeinated', 158), ('sak', 7), ('mountain', 749), ('instantly', 279), ('kick', 864), ('smooth', 2599), ('samples', 191), ('but', 3302), ('feel', 3792), ('fact', 2517), ('bzzagent', 9), ('really', 15011), ('green', 3344), ('liked', 2471), ('coffees', 1235), ('very', 2899), ('downside', 313), ('cup', 5942), ('syrups', 234), ('plus', 2240), ('perfected', 18), ('twice', 1092)]\n",
            "##################\n",
            "[[150, 2582, 11, 11, 150, 143, 363, 540, 323, 532, 157, 98, 25, 93, 16, 745]]\n",
            "[[548, 1035, 498, 8, 67, 8, 310, 68, 296, 2683, 553, 278, 1425, 4609, 579, 3542, 278, 8, 3, 22, 19, 239, 9, 310, 25, 27, 296, 1098, 1573, 22]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2ufLQRw9yxl",
        "colab_type": "text"
      },
      "source": [
        "Lets see what is the average length of sentences. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVLallaz7Jz2",
        "colab_type": "code",
        "outputId": "94563c79-5cba-425c-efda-ff45155a6a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(sum(map(len, text_to_seq_train[:245481])))\n",
        "print (\"Average length of sentences are:\")\n",
        "print (4025586/100500)\n",
        "print (\"###############\")\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4076411\n",
            "Average length of sentences are:\n",
            "40.05558208955224\n",
            "###############\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6YtbIvBGyBI",
        "colab_type": "text"
      },
      "source": [
        "Also lets see sentence with highset number of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTC6r_QcGT8S",
        "colab_type": "code",
        "outputId": "d76433c3-b0d6-4351-db7d-4fdea6eab958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def FindMaxLength(lst): \n",
        "    maxList = max((x) for x in lst) \n",
        "    maxLength = max(len(x) for x in lst ) \n",
        "  \n",
        "    return maxList, maxLength\n",
        "\n",
        "print(FindMaxLength(text_to_seq_train)) \n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([4997, 674, 3596, 4997, 3596, 693, 1037, 1193, 3523, 2236, 22, 1, 487, 450, 162, 1306, 480, 451, 288, 74, 1011, 15, 302, 457, 555, 20, 305, 999, 693, 1037, 458, 28, 217, 1, 21], 1075)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6piWp-JIKAk",
        "colab_type": "code",
        "outputId": "d6c76943-a6e6-493b-eb15-5966ec5ea09a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "max_review_length = 300\n",
        "X_train = sequence.pad_sequences(text_to_seq_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(text_to_seq_test, maxlen=max_review_length)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_train[1])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100500, 300)\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    4  143\n",
            "   84  168   96    7   16  134  396 2006   96  544  672    2   74  143\n",
            "   60  480  544  552  405  374]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCrV-pJbtYGQ",
        "colab_type": "text"
      },
      "source": [
        "Lets Try Single Layer LSTM first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pmwUYoPtc3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e2ca3220-5815-405c-8827-5f6d6c0c64ae"
      },
      "source": [
        "import warnings\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 512\n",
        "\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "embed_vector_length = 32\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(5000, embed_vector_length, input_length=max_review_length,embeddings_initializer='random_normal'))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(LSTM(100))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(\"Printing the Model Summary\")\n",
        "print(model1.summary())\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing the Model Summary\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 300, 32)           160000    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 300, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,701\n",
            "Trainable params: 213,501\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z3IegTotdDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "1cd7c1d0-f646-4b13-c537-ba13afb33f01"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=3)]\n",
        "\n",
        "import warnings\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "\n",
        "history1=model1.fit(X_train, y_train,batch_size=batch_size,epochs=epochs,callbacks=callbacks,verbose=1,validation_data=(X_test, y_test))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 100500 samples, validate on 49500 samples\n",
            "Epoch 1/10\n",
            "100500/100500 [==============================] - 104s 1ms/step - loss: 0.3067 - acc: 0.8726 - val_loss: 0.2327 - val_acc: 0.9190\n",
            "Epoch 2/10\n",
            "100500/100500 [==============================] - 103s 1ms/step - loss: 0.1660 - acc: 0.9378 - val_loss: 0.2284 - val_acc: 0.9166\n",
            "Epoch 3/10\n",
            "100500/100500 [==============================] - 104s 1ms/step - loss: 0.1481 - acc: 0.9434 - val_loss: 0.1720 - val_acc: 0.9394\n",
            "Epoch 4/10\n",
            "100500/100500 [==============================] - 103s 1ms/step - loss: 0.1326 - acc: 0.9499 - val_loss: 0.1644 - val_acc: 0.9347\n",
            "Epoch 5/10\n",
            "100500/100500 [==============================] - 104s 1ms/step - loss: 0.1188 - acc: 0.9545 - val_loss: 0.1844 - val_acc: 0.9342\n",
            "Epoch 6/10\n",
            "100500/100500 [==============================] - 100s 995us/step - loss: 0.1080 - acc: 0.9586 - val_loss: 0.1618 - val_acc: 0.9424\n",
            "Epoch 7/10\n",
            "100500/100500 [==============================] - 98s 975us/step - loss: 0.1028 - acc: 0.9605 - val_loss: 0.1614 - val_acc: 0.9391\n",
            "Epoch 8/10\n",
            "100500/100500 [==============================] - 98s 976us/step - loss: 0.0956 - acc: 0.9631 - val_loss: 0.1750 - val_acc: 0.9411\n",
            "Epoch 9/10\n",
            "100500/100500 [==============================] - 97s 970us/step - loss: 0.0878 - acc: 0.9659 - val_loss: 0.1803 - val_acc: 0.9413\n",
            "Epoch 10/10\n",
            "100500/100500 [==============================] - 98s 974us/step - loss: 0.0806 - acc: 0.9687 - val_loss: 0.1803 - val_acc: 0.9389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p7Vmyb8V2YNA",
        "colab": {}
      },
      "source": [
        "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
        "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
        "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    fig.canvas.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iHoS2KE22YNG",
        "colab": {}
      },
      "source": [
        "x = list(range(1,epochs+1))\n",
        "\n",
        "%matplotlib notebook\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "scores1 = model1.evaluate(X_test, y_test, verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1aadbb1b-867e-4fb6-b923-9fc9514045c5",
        "id": "8CPpe_yf2YNK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "print('Test score:', scores1[0]) \n",
        "print('Test accuracy:', scores1[1])\n",
        "\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
        "\n",
        "# list of epoch numbers\n",
        "vy1 = history1.history['val_loss']\n",
        "ty1 = history1.history['loss']\n",
        "plt_dynamic(x, vy1, ty1, ax)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.1802538271431971\n",
            "Test accuracy: 0.9388686868542373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBGGMMSYoSxDGGGOCsgRhjDEmqP8HwccBWoFMyhQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3H8zBG72v3x",
        "colab_type": "text"
      },
      "source": [
        "Now lets dig in 2 layer LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ilcmqSxYoLE",
        "colab_type": "code",
        "outputId": "a10474d6-b5d6-49ba-b397-c220acb934a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "import warnings\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 512\n",
        "\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "embed_vector_length = 32\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(5000, embed_vector_length, input_length=max_review_length,embeddings_initializer='random_normal'))\n",
        "model2.add(Dropout(0.3))\n",
        "model2.add(LSTM(100, return_sequences=True))\n",
        "model2.add(Dropout(0.3))\n",
        "model2.add(LSTM(100))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(\"Printing the Model Summary\")\n",
        "print(model2.summary())\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing the Model Summary\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 300, 32)           160000    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 300, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 300, 100)          53200     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 300, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 294,101\n",
            "Trainable params: 293,901\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qibcfH9QMloO",
        "colab_type": "text"
      },
      "source": [
        "https://chrisalbon.com/deep_learning/keras/neural_network_early_stopping/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drf5-njE9-rS",
        "colab_type": "code",
        "outputId": "22205170-ae43-4ff6-ff11-8dfdee2b7c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=3)]\n",
        "\n",
        "import warnings\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "\n",
        "history2=model2.fit(X_train, y_train,batch_size=batch_size,epochs=epochs,callbacks=callbacks,verbose=1,validation_data=(X_test, y_test))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 100500 samples, validate on 49500 samples\n",
            "Epoch 1/10\n",
            "100500/100500 [==============================] - 197s 2ms/step - loss: 0.3352 - acc: 0.8631 - val_loss: 0.1803 - val_acc: 0.9318\n",
            "Epoch 2/10\n",
            "100500/100500 [==============================] - 195s 2ms/step - loss: 0.1688 - acc: 0.9366 - val_loss: 0.1670 - val_acc: 0.9359\n",
            "Epoch 3/10\n",
            "100500/100500 [==============================] - 197s 2ms/step - loss: 0.1446 - acc: 0.9454 - val_loss: 0.1636 - val_acc: 0.9343\n",
            "Epoch 4/10\n",
            "100500/100500 [==============================] - 200s 2ms/step - loss: 0.1303 - acc: 0.9508 - val_loss: 0.1895 - val_acc: 0.9278\n",
            "Epoch 5/10\n",
            "100500/100500 [==============================] - 203s 2ms/step - loss: 0.1217 - acc: 0.9534 - val_loss: 0.1839 - val_acc: 0.9301\n",
            "Epoch 6/10\n",
            "100500/100500 [==============================] - 204s 2ms/step - loss: 0.1108 - acc: 0.9576 - val_loss: 0.1582 - val_acc: 0.9402\n",
            "Epoch 7/10\n",
            "100500/100500 [==============================] - 206s 2ms/step - loss: 0.1032 - acc: 0.9604 - val_loss: 0.1562 - val_acc: 0.9411\n",
            "Epoch 8/10\n",
            "100500/100500 [==============================] - 206s 2ms/step - loss: 0.0976 - acc: 0.9620 - val_loss: 0.1698 - val_acc: 0.9397\n",
            "Epoch 9/10\n",
            "100500/100500 [==============================] - 206s 2ms/step - loss: 0.0880 - acc: 0.9662 - val_loss: 0.1772 - val_acc: 0.9432\n",
            "Epoch 10/10\n",
            "100500/100500 [==============================] - 206s 2ms/step - loss: 0.0822 - acc: 0.9683 - val_loss: 0.1750 - val_acc: 0.9403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BAu2eBEg26hu",
        "colab": {}
      },
      "source": [
        "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
        "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
        "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    fig.canvas.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B38rutiC26h2",
        "colab": {}
      },
      "source": [
        "x = list(range(1,epochs+1))\n",
        "\n",
        "%matplotlib notebook\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "scores2 = model2.evaluate(X_test, y_test, verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4f7b2245-6189-4306-8e20-cdcce29b0140",
        "id": "fPG_KEtj26h9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "print('Test score:', scores2[0]) \n",
        "print('Test accuracy:', scores2[1])\n",
        "\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
        "\n",
        "# list of epoch numbers\n",
        "vy2 = history2.history['val_loss']\n",
        "ty2 = history2.history['loss']\n",
        "plt_dynamic(x, vy2, ty2, ax)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.1749505036221911\n",
            "Test accuracy: 0.9403434343289847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGOMCckShDHGmJD+H94LAWb9TkzcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lUanROI4Dcc",
        "colab_type": "text"
      },
      "source": [
        "Conclusion:\n",
        "\n",
        "Both the model single and double layer LSTM performed very well. Both being around 95% accurate"
      ]
    }
  ]
}